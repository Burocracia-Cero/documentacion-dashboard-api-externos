# 4. Procesos de Env√≠o de Informaci√≥n

> üí° **Recomendaci√≥n:** Para evitar lentitud o saturaci√≥n, programe el env√≠o de datos en horarios de baja demanda (por ejemplo, durante la noche o fuera del horario laboral). As√≠ asegura una transferencia eficiente y sin afectar el rendimiento de sus sistemas.

## 4.1 Carga hist√≥rica

La carga hist√≥rica es el primer paso para integrar su informaci√≥n al tablero. Consiste en enviar todas las solicitudes hist√≥ricas desde el **01/01/2020** (o desde la fecha m√°s antigua que tenga disponible). Este proceso se realiza una sola vez y puede hacerse en varios env√≠os por lotes (por ejemplo, mes a mes) hasta completar toda la carga inicial.

> üìÖ **Importante:** Solo env√≠e solicitudes con fecha igual o posterior al **01/01/2020**. Si no tiene datos desde esa fecha, env√≠e las solicitudes m√°s antiguas que tenga en su sistema.

### 4.1.1 Ejemplo - Configuraci√≥n de Env√≠o de Carga Hist√≥rica

```python
import schedule
import time
import logging
from datetime import datetime, timedelta
import requests

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Funci√≥n para enviar un lote de solicitudes hist√≥ricas con reintentos y backoff exponencial
def send_historical_batch(batch, max_retries=3):
    retry_count = 0
    while retry_count < max_retries:
        try:
            # Aqu√≠ se debe implementar la l√≥gica para enviar el lote al endpoint real
            send_data_to_endpoint(batch)  # Reemplazar con la funci√≥n real de env√≠o
            logger.info("‚úÖ Lote enviado correctamente")
            break
        except Exception as e:
            retry_count += 1
            wait_time = 2 ** retry_count  # Backoff exponencial: 2, 4, 8, ... segundos
            logger.error(f"‚ùå Intento {retry_count}/{max_retries} fallido: {str(e)}")
            if retry_count < max_retries:
                logger.info(f"Esperando {wait_time} segundos antes del siguiente intento...")
                time.sleep(wait_time)
    else:
        logger.error(f"‚ùå Se abandon√≥ el lote despu√©s de {max_retries} intentos fallidos")

# Funci√≥n para obtener el primer d√≠a del siguiente mes
def next_month(date):
    if date.month == 12:
        return date.replace(year=date.year + 1, month=1, day=1)
    else:
        return date.replace(month=date.month + 1, day=1)

# Funci√≥n principal para obtener y enviar todos los lotes hist√≥ricos mes por mes
# Versi√≥n simplificada

def send_all_historical_data():
    start_date = datetime(2020, 1, 1)
    end_date = datetime.now()
    current = start_date
    while current < end_date:
        next_period = min(next_month(current), end_date)
        batch = get_historical_batch(current, next_period)  # Debe implementar esta funci√≥n
        send_historical_batch(batch)
        current = next_period

schedule.every().day.at("02:00").do(send_all_historical_data)

def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)  # Verificar cada minuto si hay tareas pendientes

if __name__ == "__main__":
    run_scheduler()
```

## 4.2 Env√≠o diario

El env√≠o diario consiste en reportar, una vez al d√≠a, √∫nicamente la informaci√≥n de las solicitudes que hayan cambiado de estado en el d√≠a actual. Este proceso es recurrente y obligatorio para mantener la informaci√≥n sincronizada y actualizada en el tablero de monitoreo.

El sistema debe enviar informaci√≥n cada **24 horas** para mantener sincronizados los datos entre sistemas.

### 4.2.1 Ejemplo - Configuraci√≥n de Env√≠o diario

```python
import schedule
import time
from datetime import datetime, timedelta
import requests
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def send_hourly_data(max_retries=3):
    current_hour = datetime.now()
    previous_hour = current_hour - timedelta(hours=1)
    
    # Obtener datos del intervalo de la √∫ltima hora
    interval_data = get_data_in_interval(previous_hour, current_hour)
    
    # Enviar datos con reintentos y backoff exponencial
    retry_count = 0
    while retry_count < max_retries:
        try:
            send_data_to_endpoint(interval_data)
            logger.info("‚úÖ Datos enviados correctamente")
            break
        except Exception as e:
            retry_count += 1
            wait_time = 2 ** retry_count  # 2, 4, 8, ... segundos
            logger.error(f"‚ùå Intento {retry_count}/{max_retries} fallido: {str(e)}")
            if retry_count < max_retries:
                logger.info(f"Esperando {wait_time} segundos antes del siguiente intento...")
                time.sleep(wait_time)
            else:
                logger.error(f"‚ùå Se abandon√≥ despu√©s de {max_retries} intentos fallidos")

# Programar la tarea para ejecutar cada 24 horas
schedule.every(24).hour.do(send_hourly_data)

# Bucle principal para mantener el programa en ejecuci√≥n
def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)  # Verificar cada minuto si hay tareas pendientes

# Ejecutar en un hilo separado o como proceso principal
if __name__ == "__main__":
    run_scheduler()
```

---

**[‚¨ÖÔ∏è Atr√°s](03-envio-solicitudes.md) | [Siguiente ‚û°Ô∏è](05-consideraciones-adicionales.md)**
